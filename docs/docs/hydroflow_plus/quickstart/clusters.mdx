---
sidebar_position: 3
---
import CodeBlock from '@theme/CodeBlock';
import firstTenClusterSrc from '!!raw-loader!../../../../template/hydroflow_plus/src/first_ten_cluster.rs';
import firstTenClusterExample from '!!raw-loader!../../../../template/hydroflow_plus/examples/first_ten_cluster.rs';
import { getLines, extractOutput } from '../../../src/util';

# Scaling with Clusters
So far, we have looked at distributed systems where there is a single process running each piece of the compute graph -- **compute parallelism** (like pipelining). However, we can also use Hydroflow+ to run the same computation on multiple processes -- achieving **data parallelism** (like replication and partitioning). This is done by creating a **cluster** of processes that all run the same subgraph.

## Dataflow with Clusters
Just like we use the `Process` type to represent a virtual handle to a single node, we can use the `Cluster` type to represent a handle to a **set of nodes** (with size unknown at compile-time).

A `Stream` materialized on a `Cluster` can be thought of as SIMD-style programming, where the stream represents many independent streams on each member of the cluster, and each transformation of the stream performs the transformation on each cluster member.

To start, we set up a new module in `first_ten_cluster.rs` with a dataflow program that takes in a `Process` for a leader and `Cluster` for a set of workers.

<CodeBlock language="rust" title="src/first_ten_cluster.rs">{getLines(firstTenClusterSrc, 1, 6)}</CodeBlock>

We start by materializing a stream of numbers on the `leader`, as before. But rather than sending the stream to a single process, we will instead _distribute_ the data to each member of the cluster using `round_robin_bincode`. This API sends data to a `cluster` in a round-robin fashion by using the order of elements to determine which cluster member the element is sent to.

:::info

There are a variety of APIs for sending data to and reciving data from clusters. For example, we can `broadcast_bincode` to send copies to all members, or use the existing `send_bincode` if we have a custom algorithm to determine which cluster member should receive a piece of data.

:::

<CodeBlock language="rust" title="src/first_ten_cluster.rs">{getLines(firstTenClusterSrc, 7, 9)}</CodeBlock>

On each cluster member, we will then do some work to transform the data (using `map`) and log out the transformed values locally (using `inspect`, which is useful for debugging logic).

<CodeBlock language="rust" title="src/first_ten_cluster.rs">{getLines(firstTenClusterSrc, 10, 11)}</CodeBlock>

Finally, we will send the data back to the leader. We achieve this using a variant of the APIs from before: `send_bincode_interleaved`. This is similar to `send_bincode` in that the elements are sent to the leader process, but the elements from different cluster members are mixed together into a single stream (regular `send_bincode` would emit tuples of cluster IDs and data).

<CodeBlock language="rust" title="src/first_ten_cluster.rs">{getLines(firstTenClusterSrc, 12, 14)}</CodeBlock>

## Deploying Clusters
Deployment scripts are similar to before, except that when provisioning a cluster we provide a list of deployment hosts rather than a single one. In our example, we'll launch 4 nodes for the cluster.

<CodeBlock language="rust" title="examples/first_ten_cluster.rs">{firstTenClusterExample}</CodeBlock>

We can then launch the program:
```bash
#shell-command-next-line
cargo run --example first_ten_cluster
[hydroflow_plus_template::first_ten_cluster::Worker (cluster 1) / 0] 0
[hydroflow_plus_template::first_ten_cluster::Worker (cluster 1) / 2] 4
[hydroflow_plus_template::first_ten_cluster::Worker (cluster 1) / 2] 12
[hydroflow_plus_template::first_ten_cluster::Worker (cluster 1) / 0] 8
[hydroflow_plus_template::first_ten_cluster::Worker (cluster 1) / 3] 6
[hydroflow_plus_template::first_ten_cluster::Worker (cluster 1) / 1] 2
[hydroflow_plus_template::first_ten_cluster::Worker (cluster 1) / 1] 10
[hydroflow_plus_template::first_ten_cluster::Worker (cluster 1) / 1] 18
[hydroflow_plus_template::first_ten_cluster::Leader (process 0)] 0
[hydroflow_plus_template::first_ten_cluster::Worker (cluster 1) / 0] 16
[hydroflow_plus_template::first_ten_cluster::Worker (cluster 1) / 3] 14
[hydroflow_plus_template::first_ten_cluster::Leader (process 0)] 8
[hydroflow_plus_template::first_ten_cluster::Leader (process 0)] 16
[hydroflow_plus_template::first_ten_cluster::Leader (process 0)] 2
[hydroflow_plus_template::first_ten_cluster::Leader (process 0)] 10
[hydroflow_plus_template::first_ten_cluster::Leader (process 0)] 18
[hydroflow_plus_template::first_ten_cluster::Leader (process 0)] 4
[hydroflow_plus_template::first_ten_cluster::Leader (process 0)] 12
[hydroflow_plus_template::first_ten_cluster::Leader (process 0)] 6
[hydroflow_plus_template::first_ten_cluster::Leader (process 0)] 14
```

You'll notice the round-robin distribution in action here, as each cluster log is tagged with the ID of the member (e.g. `/ 0`). In our deployment, member `0` receives values `0`, `4`, and `8`, `1`, receives `1`, `5`, and `9`, and so on.
